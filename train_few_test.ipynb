{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qin/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from CLIP.adapter import CLIP_Inplanted\n",
    "from CLIP.clip import create_model\n",
    "\n",
    "from loss import FocalLoss, BinaryDiceLoss\n",
    "\n",
    "from dataset.medical_zero import MedTestDataset, MedTrainDataset\n",
    "from dataset.medical_few import MedDataset\n",
    "\n",
    "from utils import augment, cos_sim, encode_text_with_prompt_ensemble\n",
    "from prompt import REAL_NAME\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "CLASS_INDEX = {'Brain':3, 'Liver':2, 'Retina_RESC':1, 'Retina_OCT2017':-1, 'Chest':-2, 'Histopathology':-3}\n",
    "CLASS_INDEX_INV = {3:'Brain', 2:'Liver', 1:'Retina_RESC', -1:'Retina_OCT2017', -2:'Chest', -3:'Histopathology'}\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, test_loader, text_features, seg_mem_features, det_mem_features):\n",
    "    gt_list = []\n",
    "    gt_mask_list = []\n",
    "\n",
    "    det_image_scores_zero = []\n",
    "    det_image_scores_few = []\n",
    "    \n",
    "    seg_score_map_zero = []\n",
    "    seg_score_map_few= []\n",
    "    \n",
    "    step = 0\n",
    "    for (image, y, mask) in tqdm(test_loader):\n",
    "        # step+=1\n",
    "        # if step < 80:\n",
    "        #     continue\n",
    "        image = image.to(device)\n",
    "        mask[mask > 0.5], mask[mask <= 0.5] = 1, 0\n",
    "        # print(\"mask.shape:\", mask.shape)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "            # 去掉cls token ，由于 biomedclip cls token 位置不同，此处需要对应改变\n",
    "            seg_patch_tokens = [p[:, 1:, :] for p in seg_patch_tokens]\n",
    "            det_patch_tokens = [p[:, 1:, :] for p in det_patch_tokens]\n",
    "   \n",
    "            if CLASS_INDEX[args.obj] > 0:\n",
    "\n",
    "                # few-shot, seg head\n",
    "                anomaly_maps_few_shot = []\n",
    "                for idx, p in enumerate(seg_patch_tokens):\n",
    "                    batch_cos_sim = []\n",
    "                    for b in range(p.shape[0]):\n",
    "                        cos = cos_sim(seg_mem_features[idx][b], p[b])\n",
    "                        height = int(np.sqrt(cos.shape[1]))\n",
    "                        # * 去掉cls_token\n",
    "                        anomaly_map_few_shot = torch.min((1 - cos), 0)[0].reshape(1, 1, height, height)\n",
    "                        anomaly_map_few_shot = F.interpolate(torch.tensor(anomaly_map_few_shot),\n",
    "                                                            size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                        # * 去掉\n",
    "                        batch_cos_sim.append(anomaly_map_few_shot[0].cpu().numpy())\n",
    "                        # print('batch_cos_sim.shape:', batch_cos_sim[0].shape)\n",
    "                    anomaly_maps_few_shot.append(np.stack(batch_cos_sim, axis=0))\n",
    "                    # print('anomaly_maps_few_shot.shape:', anomaly_maps_few_shot[0].shape)\n",
    "                score_map_few = np.sum(anomaly_maps_few_shot, axis=0)\n",
    "                seg_score_map_few.append(score_map_few)\n",
    "                # print('seg_score_map_few.shape:', seg_score_map_few[0].shape)\n",
    "                \n",
    "                # zero-shot, seg head\n",
    "                anomaly_maps = []\n",
    "                for layer in range(len(seg_patch_tokens)):\n",
    "                    seg_patch_tokens[layer] /= seg_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "                    anomaly_map = (100.0 * seg_patch_tokens[layer] @ text_features)\n",
    "                    B, L, C = anomaly_map.shape\n",
    "                    H = int(np.sqrt(L))\n",
    "                    anomaly_map = F.interpolate(anomaly_map.permute(0, 2, 1).view(B, 2, H, H),\n",
    "                                                size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                    # print('anomaly_map.shape:', anomaly_map.shape)\n",
    "                    # 4 2 224 224\n",
    "                    anomaly_map = torch.softmax(anomaly_map, dim=1)[:, 1:2, :, :]\n",
    "                    # 4 224 224 \n",
    "                    # print('anomaly_map.shape:', anomaly_map.shape)\n",
    "                    anomaly_maps.append(anomaly_map.cpu().numpy())\n",
    "                    # print('anomaly_map.shape:', anomaly_map[0].shape)\n",
    "                    # print(len(anomaly_maps))\n",
    "                    # print('anomaly_map.shape:', anomaly_maps[0].shape)\n",
    "                # print('anomaly_maps.shape:', len(anomaly_maps))\n",
    "                \n",
    "                # print('anomaly_maps[0].shape:', anomaly_maps[0].shape)\n",
    "                score_map_zero = np.sum(anomaly_maps, axis=0)\n",
    "                # print('score_map_zero.shape:', score_map_zero.shape)\n",
    "                # print('score_map_zero.shape:', score_map_zero.shape)\n",
    "                seg_score_map_zero.append(score_map_zero)\n",
    "                # print(len(seg_score_map_zero))\n",
    "                # print('seg_score_map_zero.shape:', seg_score_map_zero[0].shape)\n",
    "                # \n",
    "\n",
    "\n",
    "            else:\n",
    "                # few-shot, det head\n",
    "                anomaly_maps_few_shot = []\n",
    "                for idx, p in enumerate(seg_patch_tokens):\n",
    "                    batch_cos_sim = []\n",
    "                    for b in range(p.shape[0]):\n",
    "                        cos = cos_sim(seg_mem_features[idx][b], p[b])\n",
    "                        # print(\"cos_shape\",cos.shape)\n",
    "                        height = int(np.sqrt(cos.shape[1]))\n",
    "                        # * 提取cls——token\n",
    "                        anomaly_map_few_shot = torch.min((1 - cos), 0)[0].reshape(1, 1, height, height)\n",
    "                        # print(\"anoma\",anomaly_map_few_shot.shape)\n",
    "                        anomaly_map_few_shot = F.interpolate(torch.tensor(anomaly_map_few_shot),\n",
    "                                                            size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                        \n",
    "                        # print(\"anoma\",anomaly_map_few_shot[0].shape)\n",
    "                        #* 去除多余维度\n",
    "                        batch_cos_sim.append(anomaly_map_few_shot[0].cpu().numpy())\n",
    "                    #     print('batch_cos_sim.shape:', batch_cos_sim[0].shape)\n",
    "                    # print(\"len\",len(batch_cos_sim))\n",
    "                    # print(\"shape_batch\",batch_cos_sim[0].shape)\n",
    "                    anomaly_maps_few_shot.append(np.stack(batch_cos_sim, axis=0))\n",
    "                #     print('anomaly_maps_few_shot.shape:', len(anomaly_maps_few_shot))\n",
    "                # print(\"shape anomaly\",len(anomaly_maps_few_shot))\n",
    "                # print(\"shapt\", anomaly_maps_few_shot[0].shape)\n",
    "                \n",
    "                # anomaly_map_few_shot 4,4,1,244,244 各特征层求和\n",
    "                anomaly_map_few_shot = np.sum(anomaly_maps_few_shot, axis=0)\n",
    "\n",
    "                # anomaly_map_few_shot 4,1,244,244\n",
    "                # print(\"shape anomaly\",len(anomaly_map_few_shot))\n",
    "                # print(\"shapt\", anomaly_map_few_shot.shape)\n",
    "                \n",
    "                # \n",
    "                score_few_det = anomaly_map_few_shot.mean(axis=(1, 2,3))\n",
    "                # print('score_few_det.shape:', score_few_det.shape)\n",
    "                det_image_scores_few.append(score_few_det)\n",
    "                # print(len(det_image_scores_few))\n",
    "\n",
    "                # zero-shot, det head\n",
    "                anomaly_score = 0\n",
    "                for layer in range(len(det_patch_tokens)):\n",
    "                    det_patch_tokens[layer] /= det_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "                    anomaly_map = (100.0 * det_patch_tokens[layer] @ text_features)\n",
    "                    anomaly_map = torch.softmax(anomaly_map, dim=-1)[:, :, 1]\n",
    "                    # print(\"shap\",anomaly_map.shape)\n",
    "                    anomaly_score += anomaly_map.mean(dim=1)\n",
    "                    # print(\"shapt\",anomaly_map.mean(dim=1))\n",
    "                    \n",
    "                det_image_scores_zero.append(anomaly_score.cpu().numpy())\n",
    "\n",
    "            # 使用tensor将mask添加到gt_mask_list中\n",
    "            gt_mask_list.append(mask.cpu().detach().numpy())\n",
    "            gt_list.extend(y.cpu().detach().numpy())\n",
    "\n",
    "            \n",
    "    # 问题不在于gt_mask_list的维度，在于seg_score_map_zero的维度被缩减了\n",
    "    gt_list = np.array(gt_list)\n",
    "    # gt-list (932,)\n",
    "    \n",
    "    # print(\"len(gt_mask_list):\", len(gt_mask_list))\n",
    "    # print(\"shape(gt_mask_list):\", gt_mask_list[-1].shape)\n",
    "\n",
    "    # print(\"shape(gt_mask_list[-1]):\", gt_mask_list[0])\n",
    "    # print(\"shape(gt_mask_list[-1]):\", gt_mask_list[-1])\n",
    "    # print(gt_mask_list[-2])\n",
    "    # print(gt_mask_list[-1])\n",
    "    #! 最后只有一个时，维度会被压缩\n",
    "    # asarray batch_size设置使得最后的对象与前面的大小不统一会报错\n",
    "    gt_mask_list = [\n",
    "        gt_mask_list[j][i] if len(gt_mask_list[j].shape) > 2 else gt_mask_list[j]\n",
    "            for j in range(len(gt_mask_list))        # 先遍历元素索引 j\n",
    "            for i in range(gt_mask_list[j].shape[0])  # 再遍历元素内部的样本索引 i\n",
    "            ]\n",
    "    # print('gt_mask_list shape:', len(gt_mask_list))\n",
    "    # print('gt_mask_list[0].shape:', gt_mask_list[-2].shape)\n",
    "    # print('gt_mask_list[-1].shape:', gt_mask_list[-1].shape)\n",
    "\n",
    "    gt_mask_list = np.asarray(gt_mask_list)\n",
    "    gt_mask_list = (gt_mask_list>0).astype(np.int_)\n",
    "    # print('gt_mask_list shape:', gt_mask_list.shape)\n",
    "    \n",
    "    # gt_mask_list = gt_mask_list[:len_gt_mask_list]\n",
    "    # gt_mask_list.shape image_nums,batch_size,224,224\n",
    "\n",
    "    if CLASS_INDEX[args.obj] > 0:\n",
    "        print(\"seg_score_map_zero shape:\", len(seg_score_map_zero))\n",
    "        print('seg_score_map_zero[0].shape:', seg_score_map_zero[0].shape)\n",
    "        seg_score_map_zero = [seg_score_map_zero[j][i] if len(seg_score_map_zero[j].shape) > 2 else seg_score_map_zero[j]\n",
    "            for j in range(len(seg_score_map_zero))        # 先遍历元素索引 j\n",
    "            for i in range(seg_score_map_zero[j].shape[0])  # 再遍历元素内部的样本索引 i\n",
    "            ]\n",
    "        seg_score_map_zero = np.array(seg_score_map_zero)\n",
    "        print('seg_score_map_zero shape:', seg_score_map_zero.shape)\n",
    "        \n",
    "        seg_score_map_few = [seg_score_map_few[j][i] if len(seg_score_map_few[j].shape) > 2 else seg_score_map_few[j]\n",
    "            for j in range(len(seg_score_map_few))        # 先遍历元素索引 j\n",
    "            for i in range(seg_score_map_few[j].shape[0])  # 再遍历元素内部的样本索引 i\n",
    "            ]\n",
    "        seg_score_map_few = np.array(seg_score_map_few)\n",
    "\n",
    "        seg_score_map_zero = (seg_score_map_zero - seg_score_map_zero.min()) / (seg_score_map_zero.max() - seg_score_map_zero.min())\n",
    "        seg_score_map_few = (seg_score_map_few - seg_score_map_few.min()) / (seg_score_map_few.max() - seg_score_map_few.min())\n",
    "        segment_scores = 0.5 * seg_score_map_zero + 0.5 * seg_score_map_few\n",
    "\n",
    "        seg_roc_auc = roc_auc_score(gt_mask_list.flatten(), segment_scores.flatten())\n",
    "        print(f'{args.obj} pAUC : {round(seg_roc_auc,4)}')\n",
    "\n",
    "        # segment_scores size (238, 4, 1, 224, 224)\n",
    "        segment_scores_flatten = segment_scores.reshape(segment_scores.shape[0] * segment_scores.shape[1], -1)\n",
    "        # return segment_scores_flatten,gt_list\n",
    "    \n",
    "        roc_auc_im = roc_auc_score(gt_list, np.max(segment_scores_flatten, axis=1))\n",
    "        print(f'{args.obj} AUC : {round(roc_auc_im, 4)}')\n",
    "\n",
    "        return seg_roc_auc + roc_auc_im\n",
    "\n",
    "    else:\n",
    "        # * 多batch展平\n",
    "        print(len(gt_list))\n",
    "        print('det_image_scores_zero shape:', len(det_image_scores_zero))\n",
    "        print(\"shape(det_image_scores_zero):\", det_image_scores_zero[0].shape)\n",
    "        print(\"shape(det_image_scores_zero):\", det_image_scores_zero[-1].shape)\n",
    "        print('det_image_scores_few shape:', len(det_image_scores_few))\n",
    "        print(\"shape(det_image_scores_few):\", det_image_scores_few[0].shape)\n",
    "        print(\"shape(det_image_scores_few):\", det_image_scores_few[-1].shape)\n",
    "        # det_image_scores_zero = [det_image_scores_zero[j][i] if len(det_image_scores_zero[j].shape) > 2 else det_image_scores_zero[j]\n",
    "        #     for j in range(len(det_image_scores_zero))        # 先遍历元素索引 j\n",
    "        #     for i in range(det_image_scores_zero[j].shape[0])  # 再遍历元素内部的样本索引 i\n",
    "        #     ]\n",
    "        # det_image_scores_few = [det_image_scores_few[j][i] if len(det_image_scores_few[j].shape) > 2 else det_image_scores_few[j]\n",
    "        #     for j in range(len(det_image_scores_few))        # 先遍历元素索引 j\n",
    "        #     for i in range(det_image_scores_few[j].shape[0])  # 再遍历元素内部的样本索引 i\n",
    "        #     ]\n",
    "        det_image_scores_zero = np.concatenate(det_image_scores_zero)\n",
    "        det_image_scores_few = np.concatenate(det_image_scores_few)\n",
    "\n",
    "        det_image_scores_zero = np.array(det_image_scores_zero)\n",
    "        det_image_scores_few = np.array(det_image_scores_few)\n",
    "        print(det_image_scores_few.shape)\n",
    "        print(det_image_scores_zero.shape)\n",
    "        \n",
    "        det_image_scores_zero = (det_image_scores_zero - det_image_scores_zero.min()) / (det_image_scores_zero.max() - det_image_scores_zero.min())\n",
    "        det_image_scores_few = (det_image_scores_few - det_image_scores_few.min()) / (det_image_scores_few.max() - det_image_scores_few.min())\n",
    "    \n",
    "        image_scores = 0.5 * det_image_scores_zero + 0.5 * det_image_scores_few\n",
    "        print(gt_list)\n",
    "        print(\">>\",image_scores)\n",
    "        img_roc_auc_det = roc_auc_score(gt_list, image_scores)\n",
    "        print(f'{args.obj} AUC : {round(img_roc_auc_det,4)}')\n",
    "\n",
    "        return img_roc_auc_det\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Testing')\n",
    "parser.add_argument('--model_name', type=str, default='biomedclip_local',)\n",
    "parser.add_argument('--pretrain', type=str, default='CLIP/ckpt/open_clip_pytorch_model.bin')\n",
    "parser.add_argument('--obj', type=str, default='Liver')\n",
    "parser.add_argument('--data_path', type=str, default='/root/data/')\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--save_model', type=int, default=1)\n",
    "parser.add_argument('--save_path', type=str, default='./ckpt/few-shot/')\n",
    "parser.add_argument('--img_size', type=int, default=224)\n",
    "parser.add_argument(\"--epoch\", type=int, default=50, help=\"epochs\")\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"learning rate\")\n",
    "parser.add_argument(\"--features_list\", type=int, nargs=\"+\", default=[3,6,9,12], help=\"features used\")\n",
    "parser.add_argument('--seed', type=int, default=111)\n",
    "parser.add_argument('--shot', type=int, default=4)\n",
    "parser.add_argument('--iterate', type=int, default=0)\n",
    "args = parser.parse_args(args=['--obj', 'Liver',  '--shot', '4', '--batch_size', '1','--data_path','../MVFA-AD/data/'])\n",
    "\n",
    "setup_seed(args.seed)\n",
    "\n",
    "# fixed feature extractor\n",
    "biomedclip_model,tokenizer = create_model(model_name=args.model_name, \n",
    "                            force_image_size=args.img_size, \n",
    "                            device=device, \n",
    "                            pretrained=args.pretrain, \n",
    "                            require_pretrained=True)\n",
    "\n",
    "biomedclip_model.eval()\n",
    "\n",
    "# 模型添加适配器\n",
    "model = CLIP_Inplanted(clip_model=biomedclip_model, features=args.features_list).to(device)\n",
    "model.eval()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# optimizer for only adapters\n",
    "seg_optimizer = torch.optim.Adam(list(model.seg_adapters.parameters()), lr=args.learning_rate, betas=(0.5, 0.999))\n",
    "det_optimizer = torch.optim.Adam(list(model.det_adapters.parameters()), lr=args.learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# losses\n",
    "loss_focal = FocalLoss()\n",
    "loss_dice = BinaryDiceLoss()\n",
    "loss_bce = torch.nn.BCEWithLogitsLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 4\n",
    "args.shot = 4\n",
    "args.obj = 'Retina_OCT2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text prompt\n",
    "with torch.cuda.amp.autocast(), torch.no_grad():\n",
    "    text_features = encode_text_with_prompt_ensemble(biomedclip_model, tokenizer, REAL_NAME[args.obj], device)\n",
    "\n",
    "\n",
    "best_result = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "kwargs = {'num_workers': 12, 'pin_memory': True} if use_cuda else {}\n",
    "test_dataset = MedDataset(args.data_path, args.obj, args.img_size, args.shot, args.iterate)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "# few-shot image augmentation\n",
    "augment_abnorm_img, augment_abnorm_mask = augment(test_dataset.fewshot_abnorm_img, test_dataset.fewshot_abnorm_mask)\n",
    "augment_normal_img, augment_normal_mask = augment(test_dataset.fewshot_norm_img)\n",
    "\n",
    "augment_fewshot_img = torch.cat([augment_abnorm_img, augment_normal_img], dim=0)\n",
    "augment_fewshot_mask = torch.cat([augment_abnorm_mask, augment_normal_mask], dim=0)\n",
    "\n",
    "augment_fewshot_label = torch.cat([torch.Tensor([1] * len(augment_abnorm_img)), torch.Tensor([0] * len(augment_normal_img))], dim=0)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(augment_fewshot_img, augment_fewshot_mask, augment_fewshot_label)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "# memory bank construction\n",
    "support_dataset = torch.utils.data.TensorDataset(augment_normal_img)\n",
    "support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:37<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "det_image_scores_zero shape: 163\n",
      "shape(det_image_scores_zero): (4,)\n",
      "shape(det_image_scores_zero): (4,)\n",
      "det_image_scores_few shape: 163\n",
      "shape(det_image_scores_few): (4,)\n",
      "shape(det_image_scores_few): (4,)\n",
      "(652,)\n",
      "(652,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      ">> [0.8589384  0.92264676 0.8882443  0.89961255 0.78466624 0.88850856\n",
      " 0.9408308  0.792857   0.8757694  0.82456285 0.8882607  0.814929\n",
      " 0.7988766  0.88245416 0.81494796 0.8655689  0.8223808  0.8570251\n",
      " 0.8438971  0.80273426 0.83073264 0.8473806  0.89210415 0.8808732\n",
      " 0.8602971  0.90348047 0.9095459  0.8312355  0.84628594 0.916039\n",
      " 0.8900503  0.85001284 0.8643122  0.87671614 0.86147004 0.82821107\n",
      " 0.8213911  0.8930224  0.85628307 0.86772    0.83959734 0.7758981\n",
      " 0.9409931  0.8683394  0.83393705 0.86796856 0.9499894  0.86698425\n",
      " 0.8517636  0.9552616  0.8651755  0.7622363  0.8594239  0.8411466\n",
      " 0.82824445 0.8181289  0.87626326 0.8341389  0.9285026  0.8335837\n",
      " 0.8287811  0.8872379  0.94406116 0.88879645 0.9176825  0.88088685\n",
      " 0.8608229  0.7959893  0.88414335 0.82426125 0.8402816  0.9083338\n",
      " 0.8739268  0.8495717  0.91284275 0.8345393  0.8334241  0.84543014\n",
      " 0.8886734  0.8116907  0.91416955 0.8911257  0.8323344  0.8222723\n",
      " 0.8529051  0.83320475 0.83675504 0.88077134 0.865383   0.9573436\n",
      " 0.9400873  0.8322397  0.85850513 0.8168978  0.8186865  0.8344115\n",
      " 0.86721647 0.8838516  0.9048995  0.87225384 0.8552847  0.9253991\n",
      " 0.8672178  0.8164753  0.89239717 0.8774396  0.93788904 0.91921425\n",
      " 0.94934213 0.90317273 0.9349678  0.88906205 0.86878264 0.87424\n",
      " 0.89449966 0.87893605 0.9337126  0.8737799  0.8743644  0.8617481\n",
      " 0.8445153  0.9045043  0.8951782  0.9349103  0.82875836 0.8113034\n",
      " 0.92989105 0.8347355  0.824281   0.9088185  0.8335443  0.92171335\n",
      " 0.9380238  0.94831663 0.8858391  0.6743386  0.8267653  0.8701842\n",
      " 0.85927844 0.8654392  0.93294466 0.9177587  0.8225415  0.8333757\n",
      " 0.82027996 0.8100106  0.8657873  0.84306395 0.78452057 0.7369609\n",
      " 0.8281818  0.8209146  0.90022004 0.8999723  0.80230856 0.86955816\n",
      " 0.87093294 0.8580371  0.86235905 0.90183634 0.8590803  0.8676266\n",
      " 0.8846792  0.87507546 0.8577349  0.9651491  0.92874676 0.80802757\n",
      " 0.8471482  0.8999307  0.91002214 0.84456193 0.8713422  0.6360873\n",
      " 0.7265383  0.82558    0.80612147 0.8255639  0.76993096 0.87372565\n",
      " 0.8462759  0.8662416  0.69628775 0.78407127 0.17773463 0.9268222\n",
      " 0.7956145  0.83296    0.84742874 0.8848556  0.8563067  0.8302449\n",
      " 0.8673678  0.829864   0.8588276  0.7709011  0.83196914 0.8112266\n",
      " 0.87704235 0.87141573 0.7703526  0.85281277 0.79308236 0.96778655\n",
      " 0.7666532  0.6390924  0.7875985  0.7759142  0.85439765 0.8463565\n",
      " 0.8633832  0.84177893 0.7526476  0.8082534  0.7060704  0.8518493\n",
      " 0.86849    0.86560524 0.85458195 0.7673667  0.8165501  0.7789352\n",
      " 0.71799433 0.11048485 0.83686215 0.8700861  0.86673355 0.7728772\n",
      " 0.84566844 0.85112184 0.8403278  0.8095608  0.78258026 0.9004398\n",
      " 0.9184101  0.8453095  0.88697565 0.7542123  0.8438226  0.79780245\n",
      " 0.7337624  0.8633927  0.8293699  0.81895125 0.8746455  0.8696271\n",
      " 0.7333822  0.9282978  0.8570159  0.883497   0.8183994  0.84177405\n",
      " 0.8797555  0.5217836  0.8576659  0.9082579  0.79065484 0.9351361\n",
      " 0.8305638  0.7773318  0.8941064  0.7116846  0.6689222  0.74455833\n",
      " 0.8299233  0.21956404 0.8551672  0.82295996 0.85503125 0.917408\n",
      " 0.30947626 0.83093643 0.80620015 0.7877289  0.83431596 0.7873671\n",
      " 0.8004894  0.8132429  0.8430337  0.74134994 0.8777528  0.9047093\n",
      " 0.36782402 0.773172   0.72848094 0.83921266 0.85674274 0.8421209\n",
      " 0.73639524 0.78535795 0.8855268  0.8486311  0.88022697 0.724936\n",
      " 0.74353504 0.88439536 0.8739362  0.8403963  0.7089317  0.88255334\n",
      " 0.86286193 0.8899695  0.8640202  0.9038613  0.7738969  0.84677875\n",
      " 0.88361377 0.61494434 0.76722866 0.8592015  0.8643702  0.8354906\n",
      " 0.81413126 0.8234265  0.82751966 0.6833112  0.755177   0.8143928\n",
      " 0.94168377 0.91138244 0.86295426 0.7958696  0.77911127 0.56476843\n",
      " 0.8418697  0.7212345  0.5442538  0.60959584 0.8304472  0.7808627\n",
      " 0.84304136 0.759588   0.7952852  0.73630136 0.8954054  0.74687445\n",
      " 0.8049011  0.8605052  0.7795192  0.7684761  0.7144414  0.79451567\n",
      " 0.7536268  0.7509047  0.7559086  0.8752668  0.87236726 0.5760548\n",
      " 0.662657   0.9103381  0.79545057 0.         0.85112524 0.87643945\n",
      " 0.8133985  0.6685016  0.82997835 0.7660082  0.6438997  0.7382826\n",
      " 0.7740379  0.7666936  0.78665817 0.6446586  0.6671753  0.5788835\n",
      " 0.81510746 0.82642245 0.5027127  0.8783035  0.8801143  0.8670774\n",
      " 0.85368687 0.849012   0.81580484 0.76134956 0.79133046 0.73024654\n",
      " 0.71866536 0.7504398  0.78075695 0.84646857 0.759843   0.82277685\n",
      " 0.8325561  0.839296   0.83906484 0.7793221  0.83575666 0.7347168\n",
      " 0.795714   0.7859278  0.78328896 0.7759623  0.85304505 0.8576349\n",
      " 0.88454443 0.79497516 0.8878087  0.9383041  0.92556405 0.87341994\n",
      " 0.6854914  0.75827473 0.8504282  0.8227866  0.57130194 0.81714666\n",
      " 0.80270755 0.9324336  0.8670697  0.91409874 0.8651217  0.82737887\n",
      " 0.82027185 0.7395404  0.7746322  0.8280336  0.7083773  0.85193646\n",
      " 0.8742949  0.7906896  0.79659796 0.79545975 0.7892064  0.83826756\n",
      " 0.7992511  0.8095168  0.8620079  0.8504294  0.8179133  0.82437456\n",
      " 0.82119787 0.7960844  0.7883799  0.7778828  0.74900085 0.8028494\n",
      " 0.848575   0.82565176 0.8486149  0.81148744 0.7042148  0.8266846\n",
      " 0.76344216 0.8440016  0.8383747  0.85441124 0.78501177 0.8049494\n",
      " 0.8423034  0.86609256 0.8031297  0.7745348  0.79602236 0.7733512\n",
      " 0.8498542  0.8659853  0.7933943  0.76839364 0.7511036  0.8054718\n",
      " 0.8971596  0.8608457  0.826063   0.81250894 0.87292457 0.7785908\n",
      " 0.78037995 0.8154897  0.8187144  0.8026496  0.8184447  0.8348423\n",
      " 0.8636024  0.7948509  0.8233164  0.8980358  0.8971399  0.7525768\n",
      " 0.6556066  0.8013828  0.8886484  0.83798486 0.837854   0.85446537\n",
      " 0.85213006 0.8405217  0.79626125 0.8320731  0.8574852  0.7987362\n",
      " 0.7862724  0.8156582  0.85190105 0.81214887 0.7845962  0.85359967\n",
      " 0.8677749  0.80699235 0.8313706  0.8413019  0.86016774 0.9149186\n",
      " 0.8576253  0.88030326 0.8286399  0.7747154  0.82639086 0.8269893\n",
      " 0.9113187  0.87634826 0.88594437 0.9093673  0.9023771  0.84200275\n",
      " 0.8307737  0.8289851  0.8286437  0.9082943  0.7283803  0.78183013\n",
      " 0.7756709  0.84579813 0.8723668  0.8718711  0.93821347 0.8126807\n",
      " 0.85619104 0.8057681  0.790748   0.84972596 0.8972385  0.8075546\n",
      " 0.8270441  0.82889986 0.8016954  0.8852429  0.7936748  0.8166742\n",
      " 0.862064   0.8709209  0.79920816 0.8570327  0.8266355  0.80346394\n",
      " 0.81997323 0.7721454  0.8190373  0.79077274 0.8029351  0.8170724\n",
      " 0.8114412  0.76475465 0.8663626  0.7925333  0.80951566 0.827129\n",
      " 0.7674806  0.8399519  0.8345206  0.77917624 0.7582499  0.8838519\n",
      " 0.83166504 0.8543756  0.924985   0.86724883 0.81969965 0.8574964\n",
      " 0.83457977 0.78842807 0.8394213  0.8010075  0.8186259  0.757666\n",
      " 0.86253846 0.79017913 0.8707006  0.8501613  0.7745235  0.8273927\n",
      " 0.7684598  0.87347364 0.82016754 0.76686466 0.71329427 0.42561156\n",
      " 0.7979508  0.7896639  0.65526783 0.8050475  0.78624594 0.80176735\n",
      " 0.83625865 0.8964844  0.2721671  0.6724837  0.80320644 0.73205596\n",
      " 0.7792859  0.85642284 0.763868   0.79468954 0.8017421  0.7930429\n",
      " 0.81335485 0.8458822  0.7637019  0.823424   0.8265593  0.8162465\n",
      " 0.8447912  0.8129808  0.795324   0.8103569  0.702741   0.82836\n",
      " 0.8129778  0.84738433 0.7865337  0.79890347 0.89896977 0.8585415\n",
      " 0.8102317  0.8713746  0.8071353  0.80628675 0.90121603 0.8437556\n",
      " 0.79011405 0.8009281  0.8189634  0.81488943 0.7781873  0.80653894\n",
      " 0.7312627  0.70272124 0.82983065 0.7971451  0.81058306 0.8450066\n",
      " 0.85188156 0.3939983  0.78124857 0.8222691  0.79066354 0.8563157\n",
      " 0.83728445 0.86504817 0.7834741  0.79381204]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m det_mem_features \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat([det_features[j][i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,det_features[j][i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],det_features[j][i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(det_features))], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(det_features[\u001b[38;5;241m0\u001b[39m]))]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# seg_mem_features size =>  4, (image_nums * 197, embed_size) \u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_mem_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdet_mem_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m>\u001b[39m best_result:\n\u001b[1;32m     81\u001b[0m     best_result \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[81], line 225\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(args, model, test_loader, text_features, seg_mem_features, det_mem_features)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(gt_list)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m,image_scores)\n\u001b[0;32m--> 225\u001b[0m img_roc_auc_det \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AUC : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(img_roc_auc_det,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_roc_auc_det\n",
      "File \u001b[0;32m~/miniconda3/envs/MVFA/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/MVFA/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:627\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    625\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    626\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    636\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    637\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/MVFA/lib/python3.8/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/MVFA/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    print('epoch ', epoch, ':')\n",
    "\n",
    "    # loss_list = []\n",
    "    # for (image, gt, label) in train_loader:\n",
    "    #     image = image.to(device)\n",
    "    #     with torch.cuda.amp.autocast():\n",
    "    #         _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "    #         # seg_patch_tokens size { [batch_size,196,512] * 4} \n",
    "    #         seg_patch_tokens = [p[:, 1:, :] for p in seg_patch_tokens]\n",
    "    #         det_patch_tokens = [p[:, 1:, :] for p in det_patch_tokens]\n",
    "\n",
    "    #         # det loss\n",
    "    #         det_loss = 0\n",
    "    #         image_label = label.to(device)\n",
    "    #         for layer in range(len(det_patch_tokens)):\n",
    "    #             det_patch_tokens[layer] = det_patch_tokens[layer] / det_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "    #             anomaly_map = (100.0 * det_patch_tokens[layer] @ text_features)   \n",
    "    #             anomaly_map = torch.softmax(anomaly_map, dim=-1)[:, :, 1]\n",
    "    #             anomaly_score = torch.mean(anomaly_map, dim=-1)\n",
    "    #             det_loss += loss_bce(anomaly_score, image_label)\n",
    "\n",
    "    #         if CLASS_INDEX[args.obj] > 0:\n",
    "    #             # pixel level\n",
    "    #             seg_loss = 0\n",
    "    #             mask = gt.squeeze(0).to(device)\n",
    "    #             mask[mask > 0.5], mask[mask <= 0.5] = 1, 0\n",
    "    #             for layer in range(len(seg_patch_tokens)):\n",
    "    #                 seg_patch_tokens[layer] = seg_patch_tokens[layer] / seg_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "    #                 anomaly_map = (100.0 * seg_patch_tokens[layer] @ text_features)\n",
    "    #                 B, L, C = anomaly_map.shape\n",
    "    #                 H = int(np.sqrt(L))\n",
    "    #                 anomaly_map = F.interpolate(anomaly_map.permute(0, 2, 1).view(B, 2, H, H),\n",
    "    #                                             size=args.img_size, mode='bilinear', align_corners=True)\n",
    "    #                 anomaly_map = torch.softmax(anomaly_map, dim=1)\n",
    "    #                 seg_loss += loss_focal(anomaly_map, mask)\n",
    "    #                 seg_loss += loss_dice(anomaly_map[:, 1, :, :], mask)\n",
    "                \n",
    "    #             loss = seg_loss + det_loss\n",
    "    #             loss.requires_grad_(True)\n",
    "    #             seg_optimizer.zero_grad()\n",
    "    #             det_optimizer.zero_grad()\n",
    "    #             loss.backward()\n",
    "    #             seg_optimizer.step()\n",
    "    #             det_optimizer.step()\n",
    "\n",
    "    #         else:\n",
    "    #             loss = det_loss\n",
    "    #             loss.requires_grad_(True)\n",
    "    #             det_optimizer.zero_grad()\n",
    "    #             loss.backward()\n",
    "    #             det_optimizer.step()\n",
    "\n",
    "    #         loss_list.append(loss.item())\n",
    "\n",
    "    # print(\"Loss: \", np.mean(loss_list))\n",
    "\n",
    "\n",
    "    seg_features = []\n",
    "    det_features = []\n",
    "    for image in support_loader:\n",
    "        image = image[0].to(device)\n",
    "        with torch.no_grad():\n",
    "            _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "            #? seg_patch_tokens size { [batch_size,197,512] * 4}\n",
    "            \n",
    "            #! 0 -> : , 仅改变batch_size维度， 不会改变其他维度\n",
    "            seg_patch_tokens = [p.contiguous() for p in seg_patch_tokens]\n",
    "            det_patch_tokens = [p.contiguous() for p in det_patch_tokens]\n",
    "            seg_features.append(seg_patch_tokens)\n",
    "            det_features.append(det_patch_tokens)\n",
    "    # batch_size = 1时， seg_features  image_nums， 4 ， [197,embed_size]\n",
    "    # batch_size = 2时， seg_features  {image_nums * { 4 * [2 ,197,embed_size] }  }\n",
    "    #! batch_size > 1 时， seg_features 维度会缩减！\n",
    "    seg_mem_features = [torch.cat([seg_features[j][i].view(-1,seg_features[j][i].shape[-2],seg_features[j][i].shape[-1]) for j in range(len(seg_features))], dim=0) for i in range(len(seg_features[0]))]\n",
    "    det_mem_features = [torch.cat([det_features[j][i].view(-1,det_features[j][i].shape[-2],det_features[j][i].shape[-1]) for j in range(len(det_features))], dim=0) for i in range(len(det_features[0]))]\n",
    "    # seg_mem_features size =>  4, (image_nums * 197, embed_size) \n",
    "    \n",
    "    result = test(args, model, test_loader, text_features, seg_mem_features, det_mem_features)\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        print(\"Best result\\n\")\n",
    "        if args.save_model == 1:\n",
    "            ckp_path = os.path.join(args.save_path, f'{args.obj}.pth')\n",
    "            torch.save({'seg_adapters': model.seg_adapters.state_dict(),\n",
    "                        'det_adapters': model.det_adapters.state_dict()}, \n",
    "                        ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 703/968 [00:02<00:01, 197.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 728/968 [00:03<00:02, 83.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 746/968 [00:04<00:03, 62.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 760/968 [00:04<00:04, 51.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 771/968 [00:05<00:04, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 773/968 [00:05<00:01, 149.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n",
      "shape anomaly 4\n",
      "shapt torch.Size([1, 224, 224])\n",
      "shape anomaly 1\n",
      "shapt (224, 224)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 245\u001b[0m\n\u001b[1;32m    241\u001b[0m seg_mem_features \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat([seg_features[j][i] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seg_features))], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seg_features[\u001b[38;5;241m0\u001b[39m]))]\n\u001b[1;32m    242\u001b[0m det_mem_features \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat([det_features[j][i] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(det_features))], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(det_features[\u001b[38;5;241m0\u001b[39m]))]\n\u001b[0;32m--> 245\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_mem_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdet_mem_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m>\u001b[39m best_result:\n\u001b[1;32m    247\u001b[0m     best_result \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[31], line 74\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(args, model, test_loader, text_features, seg_mem_features, det_mem_features)\u001b[0m\n\u001b[1;32m     72\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos_sim(det_mem_features[idx], p)\n\u001b[1;32m     73\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(cos\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 74\u001b[0m anomaly_map_few_shot \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, height, height)\n\u001b[1;32m     75\u001b[0m anomaly_map_few_shot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(torch\u001b[38;5;241m.\u001b[39mtensor(anomaly_map_few_shot),\n\u001b[1;32m     76\u001b[0m                                         size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mimg_size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m anomaly_maps_few_shot\u001b[38;5;241m.\u001b[39mappend(anomaly_map_few_shot[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 测试原本\n",
    "args.batch_size = 1\n",
    "args.shot = 4\n",
    "def test(args, model, test_loader, text_features, seg_mem_features, det_mem_features):\n",
    "    gt_list = []\n",
    "    gt_mask_list = []\n",
    "\n",
    "    det_image_scores_zero = []\n",
    "    det_image_scores_few = []\n",
    "    \n",
    "    seg_score_map_zero = []\n",
    "    seg_score_map_few= []\n",
    "\n",
    "    step = 0\n",
    "    for (image, y, mask) in tqdm(test_loader):\n",
    "        step += 1\n",
    "        if step < 700:\n",
    "            continue\n",
    "        \n",
    "        image = image.to(device)\n",
    "        mask[mask > 0.5], mask[mask <= 0.5] = 1, 0\n",
    "\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "            seg_patch_tokens = [p[0, 1:, :] for p in seg_patch_tokens]\n",
    "            det_patch_tokens = [p[0, 1:, :] for p in det_patch_tokens]\n",
    "\n",
    "            if CLASS_INDEX[args.obj] > 0:\n",
    "\n",
    "                # few-shot, seg head\n",
    "                anomaly_maps_few_shot = []\n",
    "                for idx, p in enumerate(seg_patch_tokens):\n",
    "                    \n",
    "                    cos = cos_sim(seg_mem_features[idx], p)\n",
    "                    height = int(np.sqrt(cos.shape[1]))\n",
    "                    anomaly_map_few_shot = torch.min((1 - cos), 0)[0].reshape(1, 1, height, height)\n",
    "\n",
    "                    anomaly_map_few_shot = F.interpolate(torch.tensor(anomaly_map_few_shot),\n",
    "                                                            size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                    anomaly_maps_few_shot.append(anomaly_map_few_shot[0].cpu().numpy())\n",
    " \n",
    "                score_map_few = np.sum(anomaly_maps_few_shot, axis=0)\n",
    "                seg_score_map_few.append(score_map_few)\n",
    "\n",
    "                # zero-shot, seg head\n",
    "                anomaly_maps = []\n",
    "                for layer in range(len(seg_patch_tokens)):\n",
    "                    \n",
    "                    seg_patch_tokens[layer] /= seg_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "                    anomaly_map = (100.0 * seg_patch_tokens[layer] @ text_features).unsqueeze(0)\n",
    "        \n",
    "                    B, L, C = anomaly_map.shape\n",
    "                    H = int(np.sqrt(L))\n",
    "                    anomaly_map = F.interpolate(anomaly_map.permute(0, 2, 1).view(B, 2, H, H),\n",
    "                                                size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                    # print(\"augment_normal_imgs.shape:\", anomaly_map.shape)\n",
    "                    anomaly_map = torch.softmax(anomaly_map, dim=1)[:, 1, :, :]\n",
    "                    print(\"anomaly_map.shape:\", anomaly_map.shape)\n",
    "                    anomaly_maps.append(anomaly_map.cpu().numpy())\n",
    "                    print(len(anomaly_maps))\n",
    "                    print(\"anomaly_maps.shape:\", anomaly_maps[0].shape)\n",
    "                score_map_zero = np.sum(anomaly_maps, axis=0)\n",
    "                print(\"score_map_zero.shape:\", score_map_zero.shape)\n",
    "                seg_score_map_zero.append(score_map_zero)\n",
    "                \n",
    "\n",
    "\n",
    "            else:\n",
    "                # few-shot, det head\n",
    "                anomaly_maps_few_shot = []\n",
    "                for idx, p in enumerate(det_patch_tokens):\n",
    "                    cos = cos_sim(det_mem_features[idx], p)\n",
    "                    height = int(np.sqrt(cos.shape[1]))\n",
    "                    anomaly_map_few_shot = torch.min((1 - cos), 0)[0].reshape(1, 1, height, height)\n",
    "                    anomaly_map_few_shot = F.interpolate(torch.tensor(anomaly_map_few_shot),\n",
    "                                                            size=args.img_size, mode='bilinear', align_corners=True)\n",
    "                    anomaly_maps_few_shot.append(anomaly_map_few_shot[0].cpu().numpy())\n",
    "                print(\"shape anomaly\",len(anomaly_maps_few_shot))\n",
    "                print(\"shapt\", anomaly_map_few_shot[0].shape)\n",
    "                \n",
    "                anomaly_map_few_shot = np.sum(anomaly_maps_few_shot, axis=0)\n",
    "\n",
    "                print(\"shape anomaly\",len(anomaly_map_few_shot))\n",
    "                print(\"shapt\", anomaly_map_few_shot[0].shape)\n",
    "                \n",
    "                # print(\"sahtp\")\n",
    "                # print(\"augment_normal_img len(anomaly_map_few_shot):\", len(anomaly_map_few_shot))\n",
    "                # print(\"anomaly_map_few_shot.shape:\", anomaly_map_few_shot.shape)\n",
    "                score_few_det = anomaly_map_few_shot.mean()\n",
    "                # print(\"ss\",score_few_det)\n",
    "                # print(\"score_few_det.shape:\", score_few_det.shape)\n",
    "                det_image_scores_few.append(score_few_det)\n",
    "\n",
    "                # zero-shot, det head\n",
    "                anomaly_score = 0\n",
    "                for layer in range(len(det_patch_tokens)):\n",
    "                    det_patch_tokens[layer] /= det_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "                    anomaly_map = (100.0 * det_patch_tokens[layer] @ text_features).unsqueeze(0)\n",
    "                    anomaly_map = torch.softmax(anomaly_map, dim=-1)[:, :, 1]\n",
    "                    anomaly_score += anomaly_map.mean()\n",
    "                det_image_scores_zero.append(anomaly_score.cpu().numpy())\n",
    "\n",
    "            \n",
    "            gt_mask_list.append(mask.squeeze().cpu().detach().numpy())\n",
    "            gt_list.extend(y.cpu().detach().numpy())\n",
    "            \n",
    "\n",
    "    gt_list = np.array(gt_list)\n",
    "    gt_mask_list = np.asarray(gt_mask_list)\n",
    "    gt_mask_list = (gt_mask_list>0).astype(np.int_)\n",
    "\n",
    "\n",
    "    if CLASS_INDEX[args.obj] > 0:\n",
    "\n",
    "        seg_score_map_zero = np.array(seg_score_map_zero)\n",
    "        seg_score_map_few = np.array(seg_score_map_few)\n",
    "\n",
    "        seg_score_map_zero = (seg_score_map_zero - seg_score_map_zero.min()) / (seg_score_map_zero.max() - seg_score_map_zero.min())\n",
    "        seg_score_map_few = (seg_score_map_few - seg_score_map_few.min()) / (seg_score_map_few.max() - seg_score_map_few.min())\n",
    "\n",
    "        print(\"seg_score_map_zero.shape:\", seg_score_map_zero.shape)\n",
    "        print('seg_score_map_few.shape:', seg_score_map_few.shape)\n",
    "        segment_scores = 0.5 * seg_score_map_zero + 0.5 * seg_score_map_few\n",
    "        seg_roc_auc = roc_auc_score(gt_mask_list.flatten(), segment_scores.flatten())\n",
    "        print(f'{args.obj} pAUC : {round(seg_roc_auc,4)}')\n",
    "\n",
    "        segment_scores_flatten = segment_scores.reshape(segment_scores.shape[0], -1)\n",
    "        roc_auc_im = roc_auc_score(gt_list, np.max(segment_scores_flatten, axis=1))\n",
    "        print(f'{args.obj} AUC : {round(roc_auc_im, 4)}')\n",
    "\n",
    "        return seg_roc_auc + roc_auc_im\n",
    "\n",
    "    else:\n",
    "\n",
    "        det_image_scores_zero = np.array(det_image_scores_zero)\n",
    "        det_image_scores_few = np.array(det_image_scores_few)\n",
    "\n",
    "        det_image_scores_zero = (det_image_scores_zero - det_image_scores_zero.min()) / (det_image_scores_zero.max() - det_image_scores_zero.min())\n",
    "        det_image_scores_few = (det_image_scores_few - det_image_scores_few.min()) / (det_image_scores_few.max() - det_image_scores_few.min())\n",
    "    \n",
    "        image_scores = 0.5 * det_image_scores_zero + 0.5 * det_image_scores_few\n",
    "        img_roc_auc_det = roc_auc_score(gt_list, image_scores)\n",
    "        print(f'{args.obj} AUC : {round(img_roc_auc_det,4)}')\n",
    "\n",
    "        return img_roc_auc_det\n",
    "    \n",
    "    # load test dataset\n",
    "kwargs = {'num_workers': 12, 'pin_memory': True} if use_cuda else {}\n",
    "test_dataset = MedDataset(args.data_path, args.obj, args.img_size, args.shot, args.iterate)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "# few-shot image augmentation\n",
    "augment_abnorm_img, augment_abnorm_mask = augment(test_dataset.fewshot_abnorm_img, test_dataset.fewshot_abnorm_mask)\n",
    "augment_normal_img, augment_normal_mask = augment(test_dataset.fewshot_norm_img)\n",
    "\n",
    "augment_fewshot_img = torch.cat([augment_abnorm_img, augment_normal_img], dim=0)\n",
    "augment_fewshot_mask = torch.cat([augment_abnorm_mask, augment_normal_mask], dim=0)\n",
    "\n",
    "augment_fewshot_label = torch.cat([torch.Tensor([1] * len(augment_abnorm_img)), torch.Tensor([0] * len(augment_normal_img))], dim=0)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(augment_fewshot_img, augment_fewshot_mask, augment_fewshot_label)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "# memory bank construction\n",
    "support_dataset = torch.utils.data.TensorDataset(augment_normal_img)\n",
    "support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "best_result = 0\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "        print('epoch ', epoch, ':')\n",
    "\n",
    "        # loss_list = []\n",
    "        # for (image, gt, label) in train_loader:\n",
    "        #     image = image.to(device)\n",
    "        #     with torch.cuda.amp.autocast():\n",
    "        #         _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "        #         # seg_patch_tokens size { [batch_size,196,512] * 4} \n",
    "        #         seg_patch_tokens = [p[0, 1:, :] for p in seg_patch_tokens]\n",
    "        #         det_patch_tokens = [p[0, 1:, :] for p in det_patch_tokens]\n",
    "\n",
    "        #         # det loss\n",
    "        #         det_loss = 0\n",
    "        #         image_label = label.to(device)\n",
    "        #         for layer in range(len(det_patch_tokens)):\n",
    "        #             det_patch_tokens[layer] = det_patch_tokens[layer] / det_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "        #             anomaly_map = (100.0 * det_patch_tokens[layer] @ text_features).unsqueeze(0)    \n",
    "        #             anomaly_map = torch.softmax(anomaly_map, dim=-1)[:, :, 1]\n",
    "        #             anomaly_score = torch.mean(anomaly_map, dim=-1)\n",
    "        #             det_loss += loss_bce(anomaly_score, image_label)\n",
    "\n",
    "        #         if CLASS_INDEX[args.obj] > 0:\n",
    "        #             # pixel level\n",
    "        #             seg_loss = 0\n",
    "        #             mask = gt.squeeze(0).to(device)\n",
    "        #             mask[mask > 0.5], mask[mask <= 0.5] = 1, 0\n",
    "        #             for layer in range(len(seg_patch_tokens)):\n",
    "        #                 seg_patch_tokens[layer] = seg_patch_tokens[layer] / seg_patch_tokens[layer].norm(dim=-1, keepdim=True)\n",
    "        #                 anomaly_map = (100.0 * seg_patch_tokens[layer] @ text_features).unsqueeze(0)\n",
    "        #                 B, L, C = anomaly_map.shape\n",
    "        #                 H = int(np.sqrt(L))\n",
    "        #                 anomaly_map = F.interpolate(anomaly_map.permute(0, 2, 1).view(B, 2, H, H),\n",
    "        #                                             size=args.img_size, mode='bilinear', align_corners=True)\n",
    "        #                 anomaly_map = torch.softmax(anomaly_map, dim=1)\n",
    "        #                 seg_loss += loss_focal(anomaly_map, mask)\n",
    "        #                 seg_loss += loss_dice(anomaly_map[:, 1, :, :], mask)\n",
    "                    \n",
    "        #             loss = seg_loss + det_loss\n",
    "        #             loss.requires_grad_(True)\n",
    "        #             seg_optimizer.zero_grad()\n",
    "        #             det_optimizer.zero_grad()\n",
    "        #             loss.backward()\n",
    "        #             seg_optimizer.step()\n",
    "        #             det_optimizer.step()\n",
    "\n",
    "        #         else:\n",
    "        #             loss = det_loss\n",
    "        #             loss.requires_grad_(True)\n",
    "        #             det_optimizer.zero_grad()\n",
    "        #             loss.backward()\n",
    "        #             det_optimizer.step()\n",
    "\n",
    "        #         loss_list.append(loss.item())\n",
    "\n",
    "        # print(\"Loss: \", np.mean(loss_list))\n",
    "\n",
    "\n",
    "        seg_features = []\n",
    "        det_features = []\n",
    "        for image in support_loader:\n",
    "            image = image[0].to(device)\n",
    "            with torch.no_grad():\n",
    "                _, seg_patch_tokens, det_patch_tokens = model(image)\n",
    "\n",
    "                seg_patch_tokens = [p[0].contiguous() for p in seg_patch_tokens]\n",
    "                det_patch_tokens = [p[0].contiguous() for p in det_patch_tokens]\n",
    "                seg_features.append(seg_patch_tokens)\n",
    "                det_features.append(det_patch_tokens)\n",
    "        seg_mem_features = [torch.cat([seg_features[j][i] for j in range(len(seg_features))], dim=0) for i in range(len(seg_features[0]))]\n",
    "        det_mem_features = [torch.cat([det_features[j][i] for j in range(len(det_features))], dim=0) for i in range(len(det_features[0]))]\n",
    "        \n",
    "\n",
    "        result = test(args, model, test_loader, text_features, seg_mem_features, det_mem_features)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            print(\"Best result\\n\")\n",
    "            if args.save_model == 1:\n",
    "                ckp_path = os.path.join(args.save_path, f'{args.obj}.pth')\n",
    "                torch.save({'seg_adapters': model.seg_adapters.state_dict(),\n",
    "                            'det_adapters': model.det_adapters.state_dict()}, \n",
    "                            ckp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数组形状: (4, 4, 1, 2)\n",
      "原始数组内容:\n",
      " [[[[ 0  1]]\n",
      "\n",
      "  [[ 2  3]]\n",
      "\n",
      "  [[ 4  5]]\n",
      "\n",
      "  [[ 6  7]]]\n",
      "\n",
      "\n",
      " [[[ 8  9]]\n",
      "\n",
      "  [[10 11]]\n",
      "\n",
      "  [[12 13]]\n",
      "\n",
      "  [[14 15]]]\n",
      "\n",
      "\n",
      " [[[16 17]]\n",
      "\n",
      "  [[18 19]]\n",
      "\n",
      "  [[20 21]]\n",
      "\n",
      "  [[22 23]]]\n",
      "\n",
      "\n",
      " [[[24 25]]\n",
      "\n",
      "  [[26 27]]\n",
      "\n",
      "  [[28 29]]\n",
      "\n",
      "  [[30 31]]]]\n",
      "\n",
      "沿 axis=0 求和后形状: (4, 1, 2)\n",
      "结果:\n",
      " [[[48 52]]\n",
      "\n",
      " [[56 60]]\n",
      "\n",
      " [[64 68]]\n",
      "\n",
      " [[72 76]]]\n",
      "\n",
      "沿 axis=1 求和后形状: (4, 1, 2)\n",
      "结果:\n",
      " [[[ 12  16]]\n",
      "\n",
      " [[ 44  48]]\n",
      "\n",
      " [[ 76  80]]\n",
      "\n",
      " [[108 112]]]\n",
      "\n",
      "沿 axis=2 求和后形状: (4, 4, 2)\n",
      "结果:\n",
      " [[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]\n",
      "  [20 21]\n",
      "  [22 23]]\n",
      "\n",
      " [[24 25]\n",
      "  [26 27]\n",
      "  [28 29]\n",
      "  [30 31]]]\n",
      "\n",
      "沿 axis=3 求和后形状: (4, 4, 1)\n",
      "结果:\n",
      " [[[ 1]\n",
      "  [ 5]\n",
      "  [ 9]\n",
      "  [13]]\n",
      "\n",
      " [[17]\n",
      "  [21]\n",
      "  [25]\n",
      "  [29]]\n",
      "\n",
      " [[33]\n",
      "  [37]\n",
      "  [41]\n",
      "  [45]]\n",
      "\n",
      " [[49]\n",
      "  [53]\n",
      "  [57]\n",
      "  [61]]]\n"
     ]
    }
   ],
   "source": [
    "# 生成一段高维数组（4，4，1，2）的对于各维度的求和示例代码\n",
    "import numpy as np\n",
    "\n",
    "# 生成一个高维数组 (4,4,1,2)，填充有序数字便于观察\n",
    "arr = np.arange(4*4*1*2).reshape(4,4,1,2)\n",
    "print(\"原始数组形状:\", arr.shape)\n",
    "print(\"原始数组内容:\\n\", arr)\n",
    "\n",
    "# ----------------------------\n",
    "# 不同维度的求和示例\n",
    "# ----------------------------\n",
    "\n",
    "# 1. 沿 axis=0 求和（合并第1个维度）\n",
    "sum_axis0 = np.sum(arr, axis=0)\n",
    "print(\"\\n沿 axis=0 求和后形状:\", sum_axis0.shape)\n",
    "print(\"结果:\\n\", sum_axis0)\n",
    "\n",
    "# 2. 沿 axis=1 求和（合并第2个维度）\n",
    "sum_axis1 = np.sum(arr, axis=1)\n",
    "print(\"\\n沿 axis=1 求和后形状:\", sum_axis1.shape)\n",
    "print(\"结果:\\n\", sum_axis1)\n",
    "\n",
    "# 3. 沿 axis=2 求和（合并第3个维度）\n",
    "sum_axis2 = np.sum(arr, axis=2)\n",
    "print(\"\\n沿 axis=2 求和后形状:\", sum_axis2.shape)\n",
    "print(\"结果:\\n\", sum_axis2)\n",
    "\n",
    "# 4. 沿 axis=3 求和（合并第4个维度）\n",
    "sum_axis3 = np.sum(arr, axis=3)\n",
    "print(\"\\n沿 axis=3 求和后形状:\", sum_axis3.shape)\n",
    "print(\"结果:\\n\", sum_axis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVFA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
